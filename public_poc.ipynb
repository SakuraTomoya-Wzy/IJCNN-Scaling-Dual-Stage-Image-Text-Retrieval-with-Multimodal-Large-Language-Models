{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Qwen的分词是padding在右边的，注意哦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WuNein\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "torch.manual_seed(114514)\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Qwen-VL-Chat\", trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Qwen-VL-Chat\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "\n",
    "# Specify hyperparameters for generation\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"./Qwen-VL-Chat\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [9693, 902], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('yes no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tokenizer.from_list_format([\n",
    "    {'image': './cat.png'}, # Either a local path or an url\n",
    "    {'text': \"\"\"what is this picture?\"\"\"},\n",
    "])\n",
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")\n",
    "raw_text, context_tokens = make_context(\n",
    "    tokenizer,\n",
    "    query,\n",
    "    history=None,\n",
    "    system=\"You are a helpful assistant.\",\n",
    "    max_window_size=model.generation_config.max_window_size,\n",
    "    chat_format=model.generation_config.chat_format,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.h.to('cpu')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    images = model.transformer.visual.encode(['./1/10.png','./1/11.png','./1/12.png'])\n",
    "    assert images.shape[0] == len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 4096])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self-alignment -> image embedding 与 他的Dense Text embedding (descrption mean in a word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    (\n",
    "        'Picture 1:<img>./s0004800.jpg</img>\\nCaptions: [\\n    \"red and yellow train stopped at a station\",\\n    \"A train is stopped at the train station.\",\\n    \"A orange and red train parked at the station.\",\\n    \"a parked train sits beside a building\",\\n    \"A train sitting in a train station in a rural area.\"\\n]\\nShort negative examples that mean the exact opposite of what is described in Captions and picture (opposite meaning): ',\n",
    "        '\"a red and orange building sits beside a running train\"',\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    (\n",
    "        'Picture 1:<img>./cat.png</img>\\nThis picture means in one word:',\n",
    "        'cat',\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st dialogue turn\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': './data/flickr30_4/s0028289.jpg'}, # Either a local path or an url\n",
    "    {'text': \"\"\"Captions: [\n",
    "        \"Two men sitting on a bench on a street next to two women doing the same.\",\n",
    "        \"Two people sit on a bench leaned against a building with writing on it.\",\n",
    "        \"Many people standing and sitting on the street in front of billboards.\",\n",
    "        \"People sitting on benches beside the street.\",\n",
    "        \"Two people sit on a bench on a city street.\"\n",
    "    ]\n",
    "Short negative examples that mean the exact opposite to what is described in Captions and picture (opposite meaning): \"\"\"},\n",
    "])\n",
    "response, history = model.chat(tokenizer, query=query, history=history)\n",
    "print(response)\n",
    "# 图中是一名女子在沙滩上和狗玩耍，旁边是一只拉布拉多犬，它们处于沙滩上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen-VL理解不了这个需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "    (\n",
    "        'Picture 1:<img>./cat.png</img>\\nThis picture means in one word:',\n",
    "        'cat',\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tokenizer.from_list_format([\n",
    "    # {'image': './cat.png'}, # Either a local path or an url\n",
    "    # {'text': \"\"\"This picture means in one word: cat\"\"\"},\n",
    "    # {'image': './data/flickr30_4/s0028289.jpg'}, # Either a local path or an url\n",
    "    {'text': \"\"\"This picture means in one word:\"\"\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text, context_tokens = make_context(\n",
    "    tokenizer,\n",
    "    query,\n",
    "    history=None,\n",
    "    system=\"You are a helpful assistant.\",\n",
    "    max_window_size=model.generation_config.max_window_size,\n",
    "    chat_format=model.generation_config.chat_format,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_ids = torch.tensor([context_tokens]).to(model.device)\n",
    "    output = model(input_ids, attention_mask = input_ids.ne(tokenizer.pad_token_id), output_hidden_states = True, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[-1][:, -1, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_id = output.logits[:,-1,:].argmax(dim=-1)\n",
    "decoded_text = tokenizer.decode(predicted_token_id)\n",
    "decoded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = \"./\"\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "total = 0\n",
    "counter = 0\n",
    "# 遍历文件夹中的每个文件\n",
    "\n",
    "big = []\n",
    "\n",
    "for file in files:\n",
    "    # 确保文件是以'.json'为扩展名的JSON文件\n",
    "    if file.endswith(\".json\") and \"flickr\" in file:\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        counter += 1\n",
    "        # 打开文件并读取JSON数据\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            # 尝试解析JSON数据\n",
    "            data = json.load(json_file)\n",
    "            big.extend(data)\n",
    "\n",
    "merged_file = open('flickr30k_no3.json', 'w+', encoding='utf-8')\n",
    "\n",
    "json.dump(big,merged_file,ensure_ascii=False)\n",
    "\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = [\n",
    "'A chocolate cake with lots of candles in it.',\n",
    " 'Someone pinches a bite off of a homemade chocolate cake.',\n",
    " 'The person is getting ready to serve the cake. ',\n",
    " 'A person takes a piece of chocolate cake.',\n",
    " 'a chocolate cake with with some candy on it ',\n",
    "]# correct answer\n",
    "texts.extend(\n",
    "    [\n",
    "         'a candy with some chocolate cake on top of it',\n",
    "             \"red and yellow train stopped at a station\",\n",
    "    \"A train is stopped at the train station.\",\n",
    "    \"A orange and red train parked at the station.\",\n",
    "    \"a parked train sits beside a building\",\n",
    "    \"A train sitting in a train station in a rural area.\",\n",
    "    ]\n",
    ") # false answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")\n",
    "text_outputs = []\n",
    "for item in texts:\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'text': f\"\"\"高等学校或研究机关中指导他人学习、进修、或撰写学术论文的教师或科研人员。\\n上面这句话用一个中文词来表达是：导师。\"\"\"},\n",
    "        {'text': f\"\"\"{item}\\n上面这句话用一个中文词来表达是：\"\"\"},\n",
    "    ])\n",
    "    raw_text, context_tokens = make_context(\n",
    "        tokenizer,\n",
    "        query,\n",
    "        history=None,\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        max_window_size=model.generation_config.max_window_size,\n",
    "        chat_format=model.generation_config.chat_format,\n",
    "    )\n",
    "    tokenizer.pad_token_id = tokenizer.eod_id\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([context_tokens]).to(model.device)\n",
    "        my_text_output = model(input_ids, attention_mask = input_ids.ne(tokenizer.pad_token_id), output_hidden_states = True, return_dict=True)\n",
    "        predicted_text_token_id = my_text_output.logits[:, -1, :].argmax(dim=-1)\n",
    "        text_output = my_text_output.hidden_states[-1][:, -1, :]\n",
    "    text_outputs.append(text_output)\n",
    "temp_text_all = (torch.cat(text_outputs,dim=0).float().cpu())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 4096])\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./pixel_pic/2.png\"\n",
    "\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': './cat.png'}, # Either a local path or an url\n",
    "    {'text': \"\"\"上面这个图用一个中文词来表达是：猫。\"\"\"},\n",
    "    {'image': file_path}, # Either a local path or an url\n",
    "    {'text': \"\"\"上面这个图用一个中文词来表达是：\"\"\"},\n",
    "])\n",
    "raw_text, context_tokens = make_context(\n",
    "    tokenizer,\n",
    "    query,\n",
    "    history=None,\n",
    "    system=\"You are a helpful assistant.\",\n",
    "    max_window_size=model.generation_config.max_window_size,\n",
    "    chat_format=model.generation_config.chat_format,\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eod_id\n",
    "with torch.no_grad():\n",
    "    input_ids = torch.tensor([context_tokens]).to(model.device)\n",
    "    outputs = model(input_ids, attention_mask = input_ids.ne(tokenizer.pad_token_id), output_hidden_states = True, return_dict=True)\n",
    "    predicted_token_id = outputs.logits[:, -1, :].argmax(dim=-1)\n",
    "    image_outputs = outputs.hidden_states[-1][:, -1, :]\n",
    "\n",
    "temp_image_all = image_outputs.float().cpu()\n",
    "emb_arr.append(temp_image_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8933104276657104\n",
      "0.8911939263343811\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "cosine_sim_0_1 = 1 - cosine(emb_arr[0][0], emb_arr[1][0])\n",
    "cosine_sim_0_2 = 1 - cosine(emb_arr[0][0], emb_arr[2][0])\n",
    "\n",
    "print(cosine_sim_0_1)\n",
    "print(cosine_sim_0_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "similarity_func = lambda s1, s2: torch.nan_to_num(\n",
    "    F.cosine_similarity(torch.nan_to_num(s1), torch.nan_to_num(s2), dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5932328701019287,\n",
       "  0.6057933568954468,\n",
       "  0.5303196907043457,\n",
       "  0.6028374433517456,\n",
       "  0.6286076903343201,\n",
       "  0.5483824014663696,\n",
       "  0.34998637437820435,\n",
       "  0.2931695580482483,\n",
       "  0.3104252219200134,\n",
       "  0.2342160940170288,\n",
       "  0.2860998213291168],\n",
       " 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = similarity_func(temp_text_all, temp_image_all)\n",
    "scores.tolist(), scores.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    # \"A chocolate cake with lots of candles in it.\",\n",
    "    #  'Someone pinches a bite off of a homemade chocolate cake.',\n",
    "    #  'The person is getting ready to serve the cake. ',\n",
    "    #  'A person takes a piece of chocolate cake.',\n",
    "    #  'a chocolate cake with with some candy on it ',\n",
    "]  # correct answer\n",
    "texts.extend(\n",
    "    [\n",
    "        \"a candy with some chocolate cake on top of it\",\n",
    "        \"red and yellow train stopped at a station\",\n",
    "        \"A train is stopped at the train station.\",\n",
    "        \"A orange and red train parked at the station.\",\n",
    "        \"a parked train sits beside a building\",\n",
    "        \"A train sitting in a train station in a rural area.\",\n",
    "    ]\n",
    ")  # false answer\n",
    "\n",
    "\n",
    "file_path = \"./s0004801.jpg\"\n",
    "\n",
    "query = tokenizer.from_list_format(\n",
    "    [\n",
    "        {\"image\": file_path[:-3] + \"jpg\"},  # Either a local path or an url\n",
    "        {\"text\": \"\"\"上面这个图与下面哪个选项中的内容关系最密切，如果都没有关系，请输出None：\"\"\"},\n",
    "    ]\n",
    "    + [\n",
    "        {\"text\": str(chr(ord(\"A\") + index)) + \".\\t\" + item}\n",
    "        for index, item in enumerate(texts)\n",
    "    ] + [{\"text\": \"None.\\t\" + \"以上所有句子都不对\"}]\n",
    ")\n",
    "raw_text, context_tokens = make_context(\n",
    "    tokenizer,\n",
    "    query,\n",
    "    history=None,\n",
    "    system=\"You are a helpful assistant.\",\n",
    "    max_window_size=model.generation_config.max_window_size,\n",
    "    chat_format=model.generation_config.chat_format,\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.eod_id\n",
    "with torch.no_grad():\n",
    "    input_ids = torch.tensor([context_tokens]).to(model.device)\n",
    "    outputs = model(\n",
    "        input_ids,\n",
    "        attention_mask=input_ids.ne(tokenizer.pad_token_id),\n",
    "        output_hidden_states=True,\n",
    "        return_dict=True,\n",
    "    )\n",
    "    predicted_token_id = outputs.logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. A chocolate cake with lots of candles in it.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    \"A chocolate cake with lots of candles in it.\",\n",
    "     'Someone pinches a bite off of a homemade chocolate cake.',\n",
    "    #  'The person is getting ready to serve the cake. ',\n",
    "    #  'A person takes a piece of chocolate cake.',\n",
    "    #  'a chocolate cake with with some candy on it ',\n",
    "]  # correct answer\n",
    "texts.extend(\n",
    "    [\n",
    "        \"a candy with some chocolate cake on top of it\",\n",
    "        \"red and yellow train stopped at a station\",\n",
    "        \"A train is stopped at the train station.\",\n",
    "        \"A orange and red train parked at the station.\",\n",
    "        \"a parked train sits beside a building\",\n",
    "        \"A train sitting in a train station in a rural area.\",\n",
    "    ]\n",
    ")  # false answer\n",
    "\n",
    "# texts = [\n",
    "#     \"red and yellow train stopped at a station\",\n",
    "#     \"A train is stopped at the train station.\",\n",
    "#     \"A orange and red train parked at the station.\",\n",
    "#     # \"a parked train sits beside a building\",\n",
    "#     # \"A train sitting in a train station in a rural area.\",\n",
    "# ] # correct answer\n",
    "# texts.extend(\n",
    "#     [\n",
    "#         \"a red and yellow platform stop beside the train\",\n",
    "#         \"A red and yellow train is loading passengers at the station.\",\n",
    "#         \"a red and yellow building sits beside a running train\",\n",
    "#     ]\n",
    "# ) # false answer\n",
    "\n",
    "file_path = \"./s0004801.jpg\"\n",
    "query = tokenizer.from_list_format(\n",
    "    [\n",
    "        {\"image\": file_path[:-3] + \"jpg\"},  # Either a local path or an url\n",
    "        {\"text\": \"\"\"多项选择题：下面哪些选项正确的描述了这个图，如果都不对请输出None：\\n\"\"\"}\n",
    "        \n",
    "    ]\n",
    "    + [\n",
    "        {\"text\": str(chr(ord(\"A\") + index)) + \".\\t\" + item + \"\\n\"}\n",
    "        for index, item in enumerate(texts)\n",
    "    ] \n",
    "    + [{\"text\": \"None.\\t\" + \"以上所有描述都不对\\n\"}]\n",
    "    + [{\"text\": \"答：AB\\n\\n\"}]\n",
    "    +\n",
    "    [\n",
    "        {\"image\": file_path[:-3] + \"jpg\"},  # Either a local path or an url\n",
    "        {\"text\": \"\"\"多项选择题：下面哪些选项正确的描述了这个图，如果都不对请输出None：\\n\"\"\"}\n",
    "        \n",
    "    ]\n",
    "    + [\n",
    "        {\"text\": str(chr(ord(\"A\") + index)) + \".\\t\" + item + \"\\n\"}\n",
    "        for index, item in enumerate(texts)\n",
    "    ] \n",
    "    + [{\"text\": \"None.\\t\" + \"以上所有描述都不对\\n\"}]\n",
    "    + [{\"text\": \"答：\"}],\n",
    ")\n",
    "response, history = model.chat(tokenizer, query=query, history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture 1:<img>./s0004801.jpg</img>\n",
      "多项选择题：下面哪些选项正确的描述了这个图，如果都不对请输出None：\n",
      "A.\tA chocolate cake with lots of candles in it.\n",
      "B.\tSomeone pinches a bite off of a homemade chocolate cake.\n",
      "C.\ta candy with some chocolate cake on top of it\n",
      "D.\tred and yellow train stopped at a station\n",
      "E.\tA train is stopped at the train station.\n",
      "F.\tA orange and red train parked at the station.\n",
      "G.\ta parked train sits beside a building\n",
      "H.\tA train sitting in a train station in a rural area.\n",
      "None.\t以上所有描述都不对\n",
      "答：AB\n",
      "\n",
      "Picture 2:<img>./s0004801.jpg</img>\n",
      "多项选择题：下面哪些选项正确的描述了这个图，如果都不对请输出None：\n",
      "A.\tA chocolate cake with lots of candles in it.\n",
      "B.\tSomeone pinches a bite off of a homemade chocolate cake.\n",
      "C.\ta candy with some chocolate cake on top of it\n",
      "D.\tred and yellow train stopped at a station\n",
      "E.\tA train is stopped at the train station.\n",
      "F.\tA orange and red train parked at the station.\n",
      "G.\ta parked train sits beside a building\n",
      "H.\tA train sitting in a train station in a rural area.\n",
      "None.\t以上所有描述都不对\n",
      "答：\n"
     ]
    }
   ],
   "source": [
    "print(query) # ABC 正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D. A train is stopped at the train station.\n",
      "Picture 2:<img>./s0004800.jpg</img>\n",
      "多项选择题：下面哪些选项正确的描述了这个图的部分特征：\n",
      "A.\tA red and yellow train is loading passengers at the station.\n",
      "B.\ta red and yellow building sits beside a running train\n",
      "C.\tred and yellow train stopped at a station\n",
      "D.\tA train is stopped at the train station.\n",
      "答：C. red and yellow train stopped at a station\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    (\n",
    "        \"\"\"Picture 1:<img>./s0004801.jpg</img>\n",
    "多项选择题：下面哪些选项正确的描述了这个图的部分特征：\n",
    "A.\tA chocolate cake with lots of candles in it.\n",
    "B.\tSomeone pinches a bite off of a homemade chocolate cake.\n",
    "C.\ta candy with some chocolate cake on top of it\n",
    "答：\"\"\",\n",
    "        'AB',\n",
    "    )\n",
    "]\n",
    "\n",
    "query = \"\"\"Picture 2:<img>./s0004800.jpg</img>\n",
    "多项选择题：下面哪些选项正确的描述了这个图的部分特征：\n",
    "A.\tA red and yellow train is loading passengers at the station.\n",
    "B.\ta red and yellow building sits beside a running train\n",
    "C.\tred and yellow train stopped at a station\n",
    "D.\tA train is stopped at the train station.\n",
    "答：\"\"\"\n",
    "response, history = model.chat(tokenizer, query=query, history=history)\n",
    "print(response)\n",
    "inputs = tokenizer(query, return_tensors='pt')\n",
    "inputs = inputs.to(model.device)\n",
    "pred = model.generate(**inputs)\n",
    "response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Picture 1:<img>./s0004801.jpg</img>\\n多项选择题：下面哪些选项正确的描述了这个图的部分特征：\\nA.\\tA chocolate cake with lots of candles in it.\\nB.\\tSomeone pinches a bite off of a homemade chocolate cake.\\nC.\\ta candy with some chocolate cake on top of it\\n答：AB\\n\\nPicture 2:<img>./s0004800.jpg</img>\\n多项选择题：下面哪些选项正确的描述了这个图的部分特征：\\nA.\\tA red and yellow train is loading passengers at the station.\\nB.\\ta red and yellow building sits beside a running train\\nC.\\tred and yellow train stopped at a station\\nD.\\tA train is stopped at the train station.\\n答：',\n",
       "  'C. red and yellow train stopped at a station')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "# 定义你感兴趣的 tokens 列表\n",
    "tokens_of_interest = [str(chr(ord(\"A\") + index)) for index in range(len(texts)) ]\n",
    "\n",
    "# 将 tokens 转换为对应的 token IDs\n",
    "token_ids_of_interest = [tokenizer(token,add_special_tokens=False).input_ids[0] for token in tokens_of_interest]\n",
    "\n",
    "# 从 logits 中提取特定 token IDs 的 logits\n",
    "logits_of_interest = predicted_token_id[:, token_ids_of_interest]\n",
    "\n",
    "# 找到概率最高的 token\n",
    "max_logits, max_indices = torch.max(logits_of_interest, dim=1)\n",
    "predicted_token_id = token_ids_of_interest[max_indices.item()]\n",
    "\n",
    "# 将 token ID 转换回 token\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "print(predicted_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"./data/test\"\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "total = 0\n",
    "counter = 0\n",
    "\n",
    "temp_text_all = []\n",
    "temp_image_all = []\n",
    "texts_image_index = []\n",
    "\n",
    "# 遍历文件夹中的每个文件\n",
    "for file in files:\n",
    "    # 确保文件是以'.json'为扩展名的JSON文件\n",
    "    if file.endswith(\".txt\"):\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # 打开文件并读取JSON数据\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as txt_file:\n",
    "            captions = [x.strip() for x in txt_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A young girl wades out into the water wearing safety floatation devices on her arms.',\n",
       " 'The baby walks on the gold and sandy-colored beach with water splashing behind him.',\n",
       " 'A girl at the shore of a beach with a mountain in the distance.',\n",
       " 'Little girl in arm floaties exploring the coast line.',\n",
       " 'A child playing in the ocean.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "高等学校或研究机关中指导他人学习、进修、或撰写学术论文的教师或科研人员。\n",
      "上面这句话用一个中文词来表达是：导师。\n",
      "A young girl wades out into the water wearing safety floatation devices on her arms.\n",
      "上面这句话用一个中文词来表达是：<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "高等学校或研究机关中指导他人学习、进修、或撰写学术论文的教师或科研人员。\n",
      "上面这句话用一个中文词来表达是：导师。\n",
      "The baby walks on the gold and sandy-colored beach with water splashing behind him.\n",
      "上面这句话用一个中文词来表达是：<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qwen_generation_utils import (\n",
    "    HistoryType,\n",
    "    make_context,\n",
    "    decode_tokens,\n",
    "    get_stop_words_ids,\n",
    "    StopWordsLogitsProcessor,\n",
    ")\n",
    "sentences_batch = ['A young girl wades out into the water wearing safety floatation devices on her arms.',\n",
    " 'The baby walks on the gold and sandy-colored beach with water splashing behind him.']\n",
    "input_ids = []\n",
    "max_length = 0\n",
    "for j, sentence in enumerate(sentences_batch):\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'text': f\"\"\"高等学校或研究机关中指导他人学习、进修、或撰写学术论文的教师或科研人员。\\n上面这句话用一个中文词来表达是：导师。\\n\"\"\"},\n",
    "        {'text': f\"\"\"{sentence}\\n上面这句话用一个中文词来表达是：\"\"\"},\n",
    "    ])\n",
    "    raw_text, context_tokens = make_context(\n",
    "        tokenizer,\n",
    "        query,\n",
    "        history=None,\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        max_window_size=model.generation_config.max_window_size,\n",
    "        chat_format=model.generation_config.chat_format,\n",
    "    )\n",
    "    print(raw_text)\n",
    "    # input_id = self.tokenizer(sentence).input_ids\n",
    "    input_ids.append(context_tokens)\n",
    "    max_length = max(max_length, len(context_tokens))\n",
    "# max_length += 10\n",
    "padding_lengths = []\n",
    "\n",
    "for j in range(len(input_ids)):\n",
    "    padding_lengths.append(max_length - len(input_ids[j]))\n",
    "    input_ids[j] += [tokenizer.eod_id] * (max_length - len(input_ids[j]))\n",
    "# target += [IGNORE_TOKEN_ID] * (max_len - len(target))\n",
    "    # input_ids.append(input_id[:max_length])\n",
    "\n",
    "# batch = self.tokenizer.batch_encode_plus(\n",
    "#     sentences_batch,\n",
    "#     return_tensors=\"pt\",\n",
    "#     padding=True,\n",
    "#     max_length=max_length,\n",
    "#     truncation=max_length is not None,\n",
    "# )\n",
    "new_input_ids = torch.tensor(input_ids, dtype=torch.int).to('cuda')\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    attention_mask = new_input_ids.ne(tokenizer.eod_id)\n",
    "    hidden_states = model(\n",
    "        input_ids= new_input_ids,attention_mask = attention_mask,output_hidden_states=True, return_dict=True\n",
    "    ).hidden_states\n",
    "    last_true_indices = torch.max(attention_mask.int().cumsum(dim=1), dim=1).indices\n",
    "    outputs = [hidden_states[-1][i, index, :] for i, index in enumerate(last_true_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_batch = ['A young girl wades out into the water wearing safety floatation devices on her arms.',\n",
    " 'The baby walks on the gold and sandy-colored beach with water splashing behind him.']\n",
    "\n",
    "single_outputs = []\n",
    "\n",
    "for j, sentence in enumerate(sentences_batch):\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'text': f\"\"\"高等学校或研究机关中指导他人学习、进修、或撰写学术论文的教师或科研人员。\\n上面这句话用一个中文词来表达是：导师。\\n\"\"\"},\n",
    "        {'text': f\"\"\"{sentence}\\n上面这句话用一个中文词来表达是：\"\"\"},\n",
    "    ])\n",
    "    raw_text, context_tokens = make_context(\n",
    "        tokenizer,\n",
    "        query,\n",
    "        history=None,\n",
    "        system=\"You are a helpful assistant.\",\n",
    "        max_window_size=model.generation_config.max_window_size,\n",
    "        chat_format=model.generation_config.chat_format,\n",
    "    )\n",
    "    # print(raw_text)\n",
    "    # input_id = self.tokenizer(sentence).input_ids\n",
    "\n",
    "    # input_ids.append(input_id[:max_length])\n",
    "\n",
    "# batch = self.tokenizer.batch_encode_plus(\n",
    "#     sentences_batch,\n",
    "#     return_tensors=\"pt\",\n",
    "#     padding=True,\n",
    "#     max_length=max_length,\n",
    "#     truncation=max_length is not None,\n",
    "# )\n",
    "    input_ids = torch.tensor([context_tokens], dtype=torch.int).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        hidden_states = model(\n",
    "            input_ids= input_ids,attention_mask = input_ids.ne(tokenizer.eod_id),output_hidden_states=True, return_dict=True\n",
    "        ).hidden_states\n",
    "        output = hidden_states[-1][:, -1, :]\n",
    "    single_outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "similarity_func = lambda s1, s2: torch.nan_to_num(\n",
    "    F.cosine_similarity(torch.nan_to_num(s1), torch.nan_to_num(s2), dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9961], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([1.], device='cuda:0', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_func(single_outputs[0],outputs[0]), similarity_func(single_outputs[1],outputs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
